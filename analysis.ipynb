{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dateutil.parser as dateparser\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put filenames in as whichever made files you ran the original ipynb for\n",
    "filenames = [\"allen-p_sent.csv\", \"arnold-j_sent.csv\"]\n",
    "\n",
    "columns = [\"uid\", \"sender\", \"recipient\", \"sendtime\", \"replytime\", \\\n",
    "                           \"replyspeed\", \"messagecontent\", \"foldername\"]\n",
    "data = pd.DataFrame(columns=columns)\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(\"processed_data/\"+filename)\n",
    "    data = pd.concat([data, df], ignore_index=True)\n",
    "    # data.concat(df, ignore_index=True)\n",
    "# data.set_index('uid', drop=True, inplace=True)\n",
    "data = data.set_index('uid')\n",
    "data\n",
    "# data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['replytime'] != '-1']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# much of the code here follows this tutorial: https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
    "\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "data['messagecontent_processed'] = \\\n",
    "data['messagecontent'].map(lambda x: re.sub('[,\\.!?]', '', x))# Convert the titles to lowercase\n",
    "data['messagecontent_processed'] = \\\n",
    "data['messagecontent_processed'].map(lambda x: x.lower())# Print out the first rows of papers\n",
    "data['messagecontent_processed'].head()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data_x = data.messagecontent_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data_x))# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "data_words[:1][0].remove('message')\n",
    "data_words[:1][0].remove('original')\n",
    "data_words[:1][0].remove('sent')\n",
    "print(data_words[:1][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.recipient.unique()\n",
    "data_dict = data.to_dict('index')\n",
    "data_dict\n",
    "\n",
    "analyzed_dict = {}\n",
    "for key in data_dict.keys():\n",
    "    row = data_dict[key]\n",
    "    \n",
    "    replyspeed = pd.Timedelta(row['replyspeed']).total_seconds()\n",
    "    sender = row['sender']\n",
    "    recipient = row['recipient']\n",
    "    # replyspeed = row['replyspeed']\n",
    "    content = row['messagecontent_processed']\n",
    "    tagged = False\n",
    "    topic = ''\n",
    "    for each in data_words[:1][0][:10]:\n",
    "        if each in content:\n",
    "            topic = each\n",
    "            tagged = True\n",
    "            break\n",
    "    if not tagged:\n",
    "        topic = 'unknown'\n",
    "\n",
    "    if(sender, recipient) in analyzed_dict:\n",
    "        analyzed_dict[sender, recipient].append((topic, replyspeed))\n",
    "    else:\n",
    "        analyzed_dict.update({(sender, recipient) : [(topic, replyspeed)]})\n",
    "    \n",
    "\n",
    "print(len(analyzed_dict.keys()))\n",
    "print(len(analyzed_dict.values()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame.from_dict(analyzed_dict, orient='index')\n",
    "headers = ['(sender,recipient)']\n",
    "for i in range(0, 48): headers.append('(email, speed)' + str(i))\n",
    "# # print(new_df.head())\n",
    "new_df.to_csv(\"processed_data/analyzed_data.csv\", header=headers)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
